{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"lab05_CKY_for_PCFG.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyP6v7BRcWD+zNI+vGYHpDD3"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"i3AHYLpyP461","colab_type":"text"},"source":["# Parsing: CKY Algorithm for PCFG\n","Before begining this short tutorial, we advise students to go through the pen-paper exercises in Lecture 6 which can be found in the following link https://github.com/ImperialNLP/NLPLabs/blob/master/lab05/lab05_ParsingLab_Questions.pdf. Detailed step-by-step solution to these exercises will be uploaded the following week.\n","\n","In this tutorial, we will implement the [Cocke–Kasami-Younger (CKY) algorithm](https://en.wikipedia.org/wiki/CYK_algorithm) to retrieve the best parse tree of a sentence for a given (toy) version of a Probabilistic Context Free Grammar (PCFG).\n","\n","We will,\n","\n","\n","1.   Understand PCFG toy-version\n","2.   Implement CKY Algorithm\n","3.   Experiment with different PCFGs\n","\n"]},{"cell_type":"markdown","metadata":{"id":"KnpQk1WYQF_m","colab_type":"text"},"source":["## 1. Probabilistic Context Free Grammar (PCFG)\n","PCFG is simply an extension of a Context Free Grammar (CFG) with probability of each rule. More formally,\n","\n","$PCFG = (T, N, S, R, q)$ where\n","\n","\n","*   $T$ is set of terminals\n","*   $N$ is set of non-terminals\n","*   $S$ is start symbol\n","*   $R$ is a set of rules of the form $X \\rightarrow Y Z$ where $X$ is a non-terminal and, $Y$ and $Z$ could be terminals or non-terminals (NOTE: we assume the rules are in [Chomsky Normal Form](https://en.wikipedia.org/wiki/Chomsky_normal_form) where there are only upto two symbols on right side of arrow $\\rightarrow$)\n","*   $q$ is the collection of probability $P(r)$ of each rule $r \\in R$ such that given a non-terminal $X$ the sum of probabilities of all rules starting with $X$ is 1. In other words, $\\sum_{Y,Z}^{} P(X \\rightarrow Y Z) = 1$\n","\n","We estimate the probability of a rule using counts from a training set of parse trees as follows\n","\n","$$P(\\tilde{X} \\rightarrow \\tilde{Y} \\tilde{Z}) = \\frac{count(\\tilde{X} \\rightarrow \\tilde{Y} \\tilde{Z})}{\\sum_{Y,Z} count(\\tilde{X} \\rightarrow Y Z)}$$\n","\n","In this tutorial, we will work with a simple toy version of a PCFG (the probabilities are made up) as given below and stored in the variable ```grammar```.\n","\n","```grammar``` is a list of rules where each rule is a list of four elements. The first element is the probability of the rule. The second element is the parent node of the rule. The third and fourth elements are the child nodes of the rule. For unary rules (one child only), the fourth element is ```None```."]},{"cell_type":"code","metadata":{"id":"4k8N1NzwQD85","colab_type":"code","colab":{}},"source":["grammar = [[1.0, 'S ', 'NP', 'VP'],\n","           [0.3, 'VP', 'V ', 'NP'],\n","           [0.7, 'VP', 'VP', 'PP'],\n","           [1.0, 'PP', 'P ', 'NP'],\n","           [1.0, 'P ', 'with', None],\n","           [1.0, 'V ', 'saw', None],\n","           [0.1, 'NP', 'NP', 'PP'],\n","           [0.2, 'NP', 'astronomers', None],\n","           [0.08, 'NP', 'ears', None],\n","           [0.15, 'NP', 'saw', None],\n","           [0.17, 'NP', 'stars', None],\n","           [0.3, 'NP', 'telescope', None]\n","           ]\n","\n","def _print_grammar(_grammar):\n","  for rule in _grammar:\n","    if rule[3] != None:\n","      print(rule[1], '-->', rule[2], rule[3], '\\t(p=%s)' % rule[0])\n","    else:\n","      print(rule[1], '-->', rule[2], '\\t(p=%s)' % rule[0])\n","\n","_print_grammar(grammar)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kI9ip4VpkALx","colab_type":"text"},"source":["**Q:** Write a simple function ```_check_rule_in_grammar(_grammar, left_child, right_child)``` which checks if there exists a rule in a PCFG ```_grammar``` such that the child nodes of the rule are ```left_child``` and ```right_child```."]},{"cell_type":"code","metadata":{"id":"CMDkcP1vTmWZ","colab_type":"code","colab":{}},"source":["def _check_rule_in_grammar(_grammar, left_child, right_child):\n","  #########\n","  # ENTER CODE HERE\n","  #########\n","\n","print(_check_rule_in_grammar(grammar, 'P ', 'NP'))  # Should return True\n","print(_check_rule_in_grammar(grammar, 'P ', 'P '))   # Should return False"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nBLZsBGNmAN0","colab_type":"text"},"source":["# 2. Cocke–Kasami-Younger (CKY) Algorithm\n","\n","CKY algorithm is a bottom-up breadth first algorithm which you must have gone through in exercise 1 of https://github.com/ImperialNLP/NLPLabs/blob/master/lab05/lab05_ParsingLab_Questions.pdf. Exercise 4 in the same document is an example of a dynamic programming version of CKY algorithm for PCFG to retrieve the most probable parse tree of a given sentence. It is not very different from the Viterbi algorithm we encountered in the previous tutorial. Pseudocode can be found in the lecture slides.\n","\n","**Q:** Implement a viterbi-like Probabilistic CKY Algorithm using the provided PCFG. Complete the code below. Look out for comments ```# ENTER CODE HERE```. What is the most probable parse tree of the sentence ***astronomers saw stars with telescope***? What is its probability?  "]},{"cell_type":"code","metadata":{"id":"aLzClxzziV3w","colab_type":"code","colab":{}},"source":["import numpy as np  # numpy is not used in the Probabilistic CKY algorithm. \n","                    # It is used only to print out the parse tree.\n","\n","def _probabilistic_CKY_parser(_sentence, _grammar):\n","  \"\"\"Returns the most probable parse tree of _sentence according to _grammar\"\"\"\n","\n","  splitted_sentence = _sentence.split()\n","\n","  viterbi = {}   # Same as pi in the pseudocode in lecture 6 \n","  backpointer = {}  # Same as bp in the pseudocode in lecture 6\n","  # We use dictionaries for convenience\n","  \n","  \n","  # Initialise. Filling diagonal cells (1,1) (2,2)... (n,n)\n","  for i in range(len(splitted_sentence)):\n","    word = splitted_sentence[i]\n","    row = i+1\n","    column = i+1 \n","    if _check_rule_in_grammar(_grammar, word, None):\n","      viterbi[row] = {column: {}}\n","      backpointer[row] = {column: {}}\n","      for rule in _grammar:\n","        if (rule[2] == word) and (rule[3] == None):\n","          parent = rule[1]\n","          probability = rule[0]\n","          viterbi[row][column][parent] = probability\n","          backpointer[row][column][parent] = {'left': [None, None, word], \n","                                              'right': [None, None, None]}\n","    else:\n","      print('Error: terminal word %s not in grammar' % word)\n","      break\n","  \n","  # Algorithm. Filling the rest of the table.\n","  # Choosing a cell (row, column) in the viterbi and backpointer tables\n","  for j in range(len(splitted_sentence)-1):\n","    add_step = j+1\n","    for i in range(len(splitted_sentence)-add_step):\n","      row = i + 1\n","      column = row + add_step\n","      viterbi[row][column] = {}\n","      backpointer[row][column] = {}\n","\n","      # Iterating over the cells in the corresponding \n","      # row and column of the cell(row, column)\n","      for k in range(add_step):\n","        left_cell_row = ## ENTER CODE HERE\n","        left_cell_column = ## ENTER CODE HERE\n","        \n","        right_cell_row = ## ENTER CODE HERE\n","        right_cell_column = ## ENTER CODE HERE\n","            \n","        # Check if a rule exists such the X -> left_cell right_cell\n","        if viterbi[left_cell_row][left_cell_column] and viterbi[right_cell_row][right_cell_column]: \n","           for left in viterbi[left_cell_row][left_cell_column].keys():\n","            for right in viterbi[right_cell_row][right_cell_column].keys():\n","              for rule in _grammar:\n","                if (rule[2] == left) and (rule[3] == right):\n","                  parent = rule[1]\n","                  probability = rule[0]\n","                  \n","                  # The viterbi update 'product' is the product of which three values?\n","                  product = ## ENTER CODE HERE\n","                  \n","                  # update the viterbi and backpointer of the cell (row,column)       \n","                  if parent not in viterbi[row][column].keys():\n","                    viterbi[row][column][parent] = product\n","                    backpointer[row][column][parent] = {'left': [left_cell_row, left_cell_column, left],\n","                                                        'right': [right_cell_row, right_cell_column, right]}\n","                  # What condition should go below?\n","                  elif ## ENTER CODE HERE:\n","                    viterbi[row][column][parent] = product\n","                    backpointer[row][column][parent] = {'left': [left_cell_row, left_cell_column, left],\n","                                                        'right': [right_cell_row, right_cell_column, right]}\n","\n","  # Retrieving the parse tree as a matrix (Ignore the code below or improve it if you want to)                                                     \n","  if 'S ' not in viterbi[1][len(splitted_sentence)].keys():\n","    print('UNGRAMMATICAL SENTENCE BASED ON GIVEN GRAMMAR\\nCANNOT BE PARSED')\n","  else:\n","    parse_matrix = np.chararray((len(splitted_sentence), len(splitted_sentence)), itemsize=2)\n","    parse_matrix[:] = '__'\n","\n","    def recursive_function(_row, _col, _parent):\n","      \"\"\"A recursive function to retrieve the parse tree from backpointer\"\"\"\n","      if _row != None:\n","        parse_matrix[_row-1][_col-1] = _parent\n","\n","        _left_row = backpointer[_row][_col][_parent]['left'][0]\n","        _left_col = backpointer[_row][_col][_parent]['left'][1]\n","        _left_parent = backpointer[_row][_col][_parent]['left'][2]\n","        recursive_function(_left_row, _left_col, _left_parent)\n","\n","        _right_row = backpointer[_row][_col][_parent]['right'][0]\n","        _right_col = backpointer[_row][_col][_parent]['right'][1]\n","        _right_parent = backpointer[_row][_col][_parent]['right'][2]\n","        recursive_function(_right_row, _right_col, _right_parent)\n","\n","    recursive_function(1,len(splitted_sentence),'S ')\n","    \n","    print('Parse Tree/Matrix:\\n')\n","    print(splitted_sentence)\n","    print(parse_matrix)\n","    print('\\nProbability =', viterbi[1][len(splitted_sentence)]['S '], '\\n\\n')\n","\n","\n","_probabilistic_CKY_parser('astronomers saw stars with telescope', grammar)  # Should return a parse tree\n","_probabilistic_CKY_parser('saw stars', grammar)    # Should not return a parse tree"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"o74A4ZJ65Yqg","colab_type":"text"},"source":["# 3. Experiment with different PCFGs\n","The probabilistic CKY parser retrieves the most probable parse tree for a given sentence according to the probabilities in the provided PCFG. If we change the probabilities in PCFG then we should get different parse trees for the same sentence.\n","\n","**Q:** Create a new PCFG called ```new_grammar``` which is identical to the old PCFG ```grammar``` except for the probability scores such that we get different parse tree for the same sentence ***astronomers saw stars with telescope***. "]},{"cell_type":"code","metadata":{"id":"Fh0W-QGUmL8x","colab_type":"code","colab":{}},"source":["new_grammar = [[?, 'S ', 'NP', 'VP'],\n","               [?, 'VP', 'V ', 'NP'],\n","               [?, 'VP', 'VP', 'PP'],\n","               [?, 'PP', 'P ', 'NP'],\n","               [?, 'P ', 'with', None],\n","               [?, 'V ', 'saw', None],\n","               [?, 'NP', 'NP', 'PP'],\n","               [?, 'NP', 'astronomers', None],\n","               [?, 'NP', 'ears', None],\n","               [?, 'NP', 'saw', None],\n","               [?, 'NP', 'stars', None],\n","               [?, 'NP', 'telescope', None]\n","              ]\n","\n","_probabilistic_CKY_parser('astronomers saw stars with telescope', new_grammar)\n","# This should be different from the parse tree retrieved earlier"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZM-sKjeb9sp_","colab_type":"text"},"source":["# Doubts? Questions? Need help with this tutorial?\n","Contact me at clala@imperial.ac.uk or chiraag.r.lala@gmail.com :)"]}]}